{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression Algorithm - Preprocessed Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import time\n",
    "import numpy as np # for array operations\n",
    "import pandas as pd # for working with DataFrames\n",
    "\n",
    "# scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split # for splitting the data\n",
    "from sklearn.metrics import mean_squared_error # for calculating the cost function\n",
    "from sklearn.ensemble import RandomForestRegressor # for building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TIME_COLUMNS = ['DATETIME_INI', 'DATETIME_FIM']\n",
    "\n",
    "dataset = pd.read_csv('../../../data/preprocessed.csv', index_col='PES_ID', parse_dates=DATE_TIME_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"DATETIME_INI\"] = dataset[\"DATETIME_INI\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "dataset[\"DATETIME_FIM\"] = dataset[\"DATETIME_FIM\"].apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop('PES_PESOUTIL', axis = 1) # Features\n",
    "y = dataset['PES_PESOUTIL']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing set (70/30)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # set up our search grid\n",
    "# param_grid = {\"n_estimators\": [1, 10, 50],\n",
    "#               \"criterion\": [\"squared_error\", \"mean_squared_error\", \"absolute_error\"],\n",
    "#               \"max_depth\": [4, 5, 6]\n",
    "# }\n",
    "\n",
    "# rfr_model = RandomForestRegressor()\n",
    "\n",
    "# # try out every combination of the above values\n",
    "# search = GridSearchCV(rfr_model, param_grid, cv=10, error_score='raise').fit(x_train, y_train)\n",
    "\n",
    "# print(\"The best hyperparameters are \",search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 50,\n",
    "    'criterion': 'squared_error',\n",
    "    'max_depth': 5,\n",
    "    'random_state': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Random Forest Regression model with 10 decision trees\n",
    "model = RandomForestRegressor(**params)\n",
    "\n",
    "# Fitting the Random Forest Regression model to the data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE (Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, model.predict(x_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def cross_validate_model(model, X, y, cv=10):\n",
    "    cv = ShuffleSplit(n_splits=cv, test_size=0.3, random_state=random.randint(0, 1000))\n",
    "    n_scores = cross_validate(estimator=model,\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=cv,\n",
    "                            scoring=('r2', 'neg_mean_squared_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True)\n",
    "    return n_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERATIONS = 5\n",
    "N_CROSS_VALIDATION = 10\n",
    "\n",
    "n_scores = []\n",
    "duration = []\n",
    "\n",
    "for _ in range(N_ITERATIONS):\n",
    "    time_start = time.time()\n",
    "    n_scores.append(cross_validate_model(model, x, y, cv=N_CROSS_VALIDATION))\n",
    "    duration.append(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(range(1,len(duration)+1), duration)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Duration (seconds)')\n",
    "plt.title('Bar Plot of Duration for Each Iteration')\n",
    "plt.show()\n",
    "\n",
    "time_training = np.mean(duration)\n",
    "time_training_std = np.std(duration)\n",
    "\n",
    "print(f\"Training time: {time_training} ± {time_training_std} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R² Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape the R2 scores\n",
    "r2_scores = [r2['test_r2'].reshape(-1, 1) for r2 in n_scores]\n",
    "\n",
    "# Plot the R2 scores\n",
    "[plt.plot(r2_score, label=f'Fold {i + 1}') for i, r2_score in enumerate(r2_scores)]\n",
    "plt.xlabel('Cross-validation fold')\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('R2 Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of R2 scores\n",
    "mean_r2_scores = [r2['test_r2'].mean() for r2 in n_scores]\n",
    "std_r2_scores = [r2['test_r2'].std() for r2 in n_scores]\n",
    "\n",
    "# Plot the mean R2 scores with error bars representing the standard deviation\n",
    "plt.errorbar(range(1, N_ITERATIONS + 1), mean_r2_scores, yerr=std_r2_scores, marker='o', linestyle='-', capsize=5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('Mean R2 Scores with Standard Deviation')\n",
    "plt.show()\n",
    "\n",
    "mean_r2 = sum(mean_r2_scores) / len(mean_r2_scores)\n",
    "std_mse = np.std(mean_r2_scores)\n",
    "\n",
    "print(\"Mean R2: {:.4f}\".format(mean_r2))\n",
    "print(\"Standard Deviation of R2: {:.4f}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each fold\n",
    "mse_scores = [-r2['test_neg_mean_squared_error'].mean() for r2 in n_scores]\n",
    "\n",
    "# Plot the MSE scores\n",
    "plt.plot(range(1, N_ITERATIONS + 1), mse_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE Scores')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of MSE scores\n",
    "mean_mse = sum(mse_scores) / len(mse_scores)\n",
    "std_mse = np.std(mse_scores)\n",
    "\n",
    "print(\"Mean MSE: {:.4f}\".format(mean_mse))\n",
    "print(\"Standard Deviation of MSE: {:.4f}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = [np.sqrt(-r2['test_neg_mean_squared_error'].mean()) for r2 in n_scores]\n",
    "\n",
    "# Plot the RMSE scores\n",
    "plt.plot(range(1, N_ITERATIONS + 1), rmse_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Scores')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of RMSE scores\n",
    "mean_rmse = sum(rmse_scores) / len(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "\n",
    "print(\"Mean RMSE: {:.4f}\".format(mean_rmse))\n",
    "print(\"Standard Deviation of RMSE: {:.4f}\".format(std_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the filename for the metrics dataset\n",
    "metrics_filename = \"../results.csv\"\n",
    "\n",
    "# Check if the metrics.csv file exists\n",
    "if os.path.exists(metrics_filename):\n",
    "    # Load the metrics dataset\n",
    "    metrics_dataset = pd.read_csv(metrics_filename, index_col='Algorithm')\n",
    "    \n",
    "    data = {\n",
    "        \"Mean R2 score\": mean_r2,\n",
    "        \"Standard deviation of R2 scores\": std_mse,\n",
    "        \"Mean MSE\": mean_mse,\n",
    "        \"Standard deviation of MSE\": std_mse,\n",
    "        \"Mean RMSE\": mean_rmse,\n",
    "        \"Standard deviation of RMSE\": std_rmse,\n",
    "        \"Mean Training time\": time_training,\n",
    "        \"Standard deviation of Training time\": time_training_std\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data, index=['RandomForestRegressor_preprocessed'])\n",
    "    \n",
    "    metrics_dataset = pd.concat([metrics_dataset, df], axis=0)\n",
    "    \n",
    "    # Save the updated metrics dataset\n",
    "    metrics_dataset.to_csv(metrics_filename, index=True, index_label='Algorithm')\n",
    "else:\n",
    "    # The metrics.csv file does not exist, print an error message\n",
    "    print(\"The metrics.csv file does not exist.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
