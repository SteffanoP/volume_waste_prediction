{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TIME_COLUMNS = ['DATETIME_INI', 'DATETIME_FIM']\n",
    "\n",
    "# Load the data\n",
    "dataset = pd.read_csv('../../../data/dataset.csv', index_col='PES_ID', parse_dates=DATE_TIME_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "dataset[\"DATETIME_INI\"] = dataset[\"DATETIME_INI\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "dataset[\"DATETIME_FIM\"] = dataset[\"DATETIME_FIM\"].apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['LOCDESCARREGO_DESC'] = dataset['LOCDESCARREGO_DESC'].astype('category')\n",
    "dataset['EMP_NOME'] = dataset['EMP_NOME'].astype('category')\n",
    "dataset['ROTA_ID'] = dataset['ROTA_ID'].astype('category')\n",
    "dataset['TPVEICULO_DESC'] = dataset['TPVEICULO_DESC'].astype('category')\n",
    "dataset['COLETA_DESC'] = dataset['COLETA_DESC'].astype('category')\n",
    "dataset['ESPECCOLETA_DESC'] = dataset['COLETA_DESC'].astype('category')\n",
    "dataset['ROTA_DESC'] = dataset['ROTA_DESC'].astype('category')\n",
    "dataset['TPCIRCUITO_DESC'] = dataset['TPCIRCUITO_DESC'].astype('category')\n",
    "dataset['LOCAL_NOME'] = dataset['LOCAL_NOME'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'PES_PESOUTIL'\n",
    "target_column = dataset.pop(target_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, target_column, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "xgr = xg.XGBRegressor(objective ='reg:squarederror',\n",
    "                      tree_method = 'hist', \n",
    "                      learning_rate = 0.2,\n",
    "                      max_depth = 5,\n",
    "                      alpha = 400,\n",
    "                      n_estimators = 500,\n",
    "                      enable_categorical = True\n",
    "                      )\n",
    "xgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, xgr.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # set up our search grid\n",
    "# param_grid = {\"max_depth\":    [5],\n",
    "#               \"tree_method\":  [\"hist\"],\n",
    "#               \"n_estimators\": [500, 600],\n",
    "#               \"learning_rate\": [0.2],\n",
    "#               \"alpha\": [400, 500]}\n",
    "\n",
    "# xgr = xg.XGBRegressor(objective ='reg:squarederror')\n",
    "\n",
    "# # try out every combination of the above values\n",
    "# search = GridSearchCV(xgr, param_grid, cv=10).fit(X_train, y_train)\n",
    "\n",
    "# print(\"The best hyperparameters are \",search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def cross_validate_model(model, X, y, cv=10):\n",
    "    cv = ShuffleSplit(n_splits=cv, test_size=0.3, random_state=random.randint(0, 1000))\n",
    "    scores = cross_validate(estimator=model,\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=cv,\n",
    "                            scoring=('r2', 'neg_mean_squared_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True\n",
    "                            )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "N_ITERATIONS = 5\n",
    "N_CROSS_VALIDATION = 10\n",
    "\n",
    "scores = []\n",
    "duration = []\n",
    "\n",
    "for _ in range(N_ITERATIONS):\n",
    "    time_start = time.time()\n",
    "    scores.append(cross_validate_model(xgr, dataset, target_column, cv=N_CROSS_VALIDATION))\n",
    "    duration.append(time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(range(1,len(duration)+1), duration)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Duration (seconds)')\n",
    "plt.title('Bar Plot of Duration for Each Iteration')\n",
    "plt.show()\n",
    "\n",
    "time_training = np.mean(duration)\n",
    "time_training_std = np.std(duration)\n",
    "\n",
    "print(f\"Training time: {time_training} Â± {time_training_std} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r2_scores = [r2['test_r2'] for r2 in scores]\n",
    "\n",
    "# Create a boxplot of the R2 scores for each iteration\n",
    "plt.boxplot(r2_scores)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('Boxplot of R2 Scores for Each Iteration')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the mean and standard deviation of the R2 scores\n",
    "r2_scores_mean = np.mean(r2_scores)\n",
    "r2_scores_std = np.std(r2_scores)\n",
    "\n",
    "print(f\"Mean R2 score: {r2_scores_mean:.4f}\")\n",
    "print(f\"Standard deviation of R2 scores: {r2_scores_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each fold\n",
    "mse_scores = [-mse['test_neg_mean_squared_error'] for mse in scores]\n",
    "plt.boxplot(mse_scores)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE score')\n",
    "plt.title('Boxplot of MSE Scores for Each Iteration')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of MSE scores\n",
    "mean_mse = np.mean([mse.mean() for mse in mse_scores])\n",
    "std_mse = np.std(mse_scores)\n",
    "\n",
    "print(\"Mean MSE: {:.4f}\".format(mean_mse))\n",
    "print(\"Standard Deviation of MSE: {:.4f}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = [-rmse['test_neg_root_mean_squared_error'] for rmse in scores]\n",
    "\n",
    "# Plot the RMSE scores\n",
    "plt.boxplot(rmse_scores)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE score')\n",
    "plt.title('Boxplot of RMSE Scores for Each Iteration')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of RMSE scores\n",
    "mean_rmse = np.mean([rmse.mean() for rmse in rmse_scores])\n",
    "std_rmse = np.std(rmse_scores)\n",
    "\n",
    "print(\"Mean RMSE: {:.4f}\".format(mean_rmse))\n",
    "print(\"Standard Deviation of RMSE: {:.4f}\".format(std_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the filename for the metrics dataset\n",
    "metrics_filename = \"../results.csv\"\n",
    "\n",
    "# Check if the metrics.csv file exists\n",
    "if os.path.exists(metrics_filename):\n",
    "    # Load the metrics dataset\n",
    "    metrics_dataset = pd.read_csv(metrics_filename, index_col='Algorithm')\n",
    "    \n",
    "    data = {\n",
    "        \"Mean R2 score\": r2_scores_mean,\n",
    "        \"Standard deviation of R2 scores\": r2_scores_std,\n",
    "        \"Mean MSE\": mean_mse,\n",
    "        \"Standard deviation of MSE\": std_mse,\n",
    "        \"Mean RMSE\": mean_rmse,\n",
    "        \"Standard deviation of RMSE\": std_rmse,\n",
    "        \"Mean Training time\": time_training,\n",
    "        \"Standard deviation of Training time\": time_training_std\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data, index=['XGBoostRegressor_raw'])\n",
    "    \n",
    "    metrics_dataset = pd.concat([metrics_dataset, df], axis=0)\n",
    "    \n",
    "    # Save the updated metrics dataset\n",
    "    metrics_dataset.to_csv(metrics_filename, index=True, index_label='Algorithm')\n",
    "else:\n",
    "    # The metrics.csv file does not exist, print an error message\n",
    "    print(\"The metrics.csv file does not exist.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
