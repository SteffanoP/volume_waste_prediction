{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_TIME_COLUMNS = ['DATETIME_INI', 'DATETIME_FIM']\n",
    "\n",
    "dataset = pd.read_csv('../data/preprocessed.csv', index_col='PES_ID', parse_dates=DATE_TIME_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"DATETIME_INI\"] = dataset[\"DATETIME_INI\"].apply(lambda x: time.mktime(x.timetuple()))\n",
    "dataset[\"DATETIME_FIM\"] = dataset[\"DATETIME_FIM\"].apply(lambda x: time.mktime(x.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_name = 'PES_PESOUTIL'\n",
    "target_column = dataset.pop(target_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.to_numpy()\n",
    "y = target_column.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": 10000,\n",
    "    \"max_iter\": 10000,\n",
    "    \"learning_rate\": 0.5,\n",
    "    \"loss\": \"squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = HistGradientBoostingRegressor(**params, categorical_features=\"from_dtype\")\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def cross_validate_model(model, X, y, cv=10):\n",
    "    cv = ShuffleSplit(n_splits=cv, test_size=0.3, random_state=random.randint(0, 1000))\n",
    "    scores = cross_validate(estimator=model,\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=cv,\n",
    "                            scoring=('r2', 'neg_mean_squared_error', 'neg_root_mean_squared_error'),\n",
    "                            return_train_score=True\n",
    "                            )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITERATIONS = 5\n",
    "N_CROSS_VALIDATION = 10\n",
    "\n",
    "scores = []\n",
    "\n",
    "for _ in range(N_ITERATIONS):\n",
    "    scores.append(cross_validate_model(reg, X, y, cv=N_CROSS_VALIDATION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape the R2 scores\n",
    "r2_scores = [r2['test_r2'].reshape(-1, 1) for r2 in scores]\n",
    "\n",
    "# Plot the R2 scores\n",
    "[plt.plot(r2_score, label=f'Fold {i + 1}') for i, r2_score in enumerate(r2_scores)]\n",
    "plt.xlabel('Cross-validation fold')\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('R2 Scores')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of R2 scores\n",
    "mean_r2_scores = [r2['test_r2'].mean() for r2 in scores]\n",
    "std_r2_scores = [r2['test_r2'].std() for r2 in scores]\n",
    "\n",
    "# Plot the mean R2 scores with error bars representing the standard deviation\n",
    "plt.errorbar(range(1, N_ITERATIONS + 1), mean_r2_scores, yerr=std_r2_scores, marker='o', linestyle='-', capsize=5)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('R2 score')\n",
    "plt.title('Mean R2 Scores with Standard Deviation')\n",
    "plt.show()\n",
    "\n",
    "mean_r2 = sum(mean_r2_scores) / len(mean_r2_scores)\n",
    "std_mse = np.std(mean_r2_scores)\n",
    "\n",
    "print(\"Mean R2: {:.4f}\".format(mean_r2))\n",
    "print(\"Standard Deviation of R2: {:.4f}\".format(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each fold\n",
    "mse_scores = [-r2['test_neg_mean_squared_error'].mean() for r2 in scores]\n",
    "\n",
    "# Plot the MSE scores\n",
    "plt.plot(range(1, N_ITERATIONS + 1), mse_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE Scores')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of MSE scores\n",
    "mean_mse = sum(mse_scores) / len(mse_scores)\n",
    "std_mse = np.std(mse_scores)\n",
    "\n",
    "print(\"Mean MSE: {:.4f}\".format(mean_mse))\n",
    "print(\"Standard Deviation of MSE: {:.4f}\".format(std_mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores = [np.sqrt(-r2['test_neg_mean_squared_error'].mean()) for r2 in scores]\n",
    "\n",
    "# Plot the RMSE scores\n",
    "plt.plot(range(1, N_ITERATIONS + 1), rmse_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE Scores')\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean and standard deviation of RMSE scores\n",
    "mean_rmse = sum(rmse_scores) / len(rmse_scores)\n",
    "std_rmse = np.std(rmse_scores)\n",
    "\n",
    "print(\"Mean RMSE: {:.4f}\".format(mean_rmse))\n",
    "print(\"Standard Deviation of RMSE: {:.4f}\".format(std_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
