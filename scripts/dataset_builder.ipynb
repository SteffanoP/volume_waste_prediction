{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Builder\n",
    "\n",
    "Takes raw data and makes a real dataset ready for preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset into pandas dataframe\n",
    "df_pesagens = pd.read_csv('../data/raw/pesagens2014.csv', sep=',')\n",
    "df_rotas = pd.read_csv('../data/raw/rotas.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pesagens.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pesagens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rotas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at both data, as well as looking at the [documentation of the data](http://dados.recife.pe.gov.br/dataset/pesagem-de-coletas-de-residuos), we know that the point of connection for both data is `ROTA_ID` attribute. \n",
    "\n",
    "We've gotta be sure that all instances from `pesagens` dataset has a valid `ROTA_ID` that is present on `roteirizacao` dataset, for this, we'll aggregate all valid data and non-valid data will be discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Rotas Data into Pesagens \n",
    "\n",
    "Now we're gonna merge both datasets into just one dataset. This is achieved by using the `merge` method from **pandas**, but, as seen in our tests, if we have duplicate indexes we may see a duplication of our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, we're gonna drop duplicate indexes present on our data, to make sure the merge is successfull and  no duplicate data is present in the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pesagens = df_pesagens.reset_index().drop_duplicates(subset='PES_ID', keep='first')\n",
    "df_rotas = df_rotas.reset_index().drop_duplicates(subset='ROTA_ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates removed, we can now merge into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_pesagens.merge(df_rotas, on='ROTA_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few data is duplicated due to the merge, that is:\n",
    "\n",
    "- `EMP_ID_x` and `EMP_ID_y`\n",
    "- `_id` and `index`\n",
    "\n",
    "We'll remove the duplicated data and keep only the attributes that stores real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'EMP_ID_x': 'EMP_ID'}, inplace=True)\n",
    "df.drop(columns=['EMP_ID_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['index_x', 'index_y'], axis=1, inplace=True)\n",
    "df.drop(['_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few adaptations\n",
    "\n",
    "Altough the dataset is merged there's a few data that needs adaptation. We have identified the following inconsistencies with the data:\n",
    "\n",
    "- `PES_DATAINI` and `PES_DATAFIM` contains only date, not datetime format\n",
    "- `PES_HRINI` and `PES_HRFIM` contains only time data, not datetime format\n",
    "\n",
    "Since **datetime** format combines both information, we'll combine those data into `DATETIME_INI` and `DATETIME_FIM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PES_DATAINI'] = df['PES_DATAINI'].apply(lambda x: x[:10])\n",
    "df['PES_DATAFIM'] = df['PES_DATAFIM'].apply(lambda x: x[:10])\n",
    "\n",
    "df['PES_HRINI'] = df['PES_HRINI'].apply(lambda x: x[11:])\n",
    "df['PES_HRFIM'] = df['PES_HRFIM'].apply(lambda x: x[11:])\n",
    "\n",
    "df['DATETIME_INI'] = pd.to_datetime(df['PES_DATAINI'] + ' ' + df['PES_HRINI'])\n",
    "df['DATETIME_FIM'] = pd.to_datetime(df['PES_DATAFIM'] + ' ' + df['PES_HRFIM'])\n",
    "\n",
    "df.drop(['PES_DATAINI', 'PES_DATAFIM', 'PES_HRINI', 'PES_HRFIM'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting our dataset\n",
    "\n",
    "Simply we're gonna export into a `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/dataset.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
